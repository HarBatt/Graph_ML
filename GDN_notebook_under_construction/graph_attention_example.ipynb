{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f705a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3372f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, heads=1, concat=True, \n",
    "                 negative_slope=0.2, dropout=0, bias=True, inter_dim=-1,**kwargs):\n",
    "        super(GraphLayer, self).__init__(aggr='add', **kwargs)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.node_dim = 0\n",
    "        self.__alpha__ = None\n",
    "        self.lin = nn.Linear(in_channels, heads * out_channels, bias=False)\n",
    "\n",
    "        self.att_i = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_j = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_em_i = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_em_j = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
    "\n",
    "        if bias and concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(heads*out_channels))\n",
    "        elif bias and not concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, embedding, return_attention_weights=False):\n",
    "        if torch.is_tensor(x):\n",
    "            x = self.lin(x)\n",
    "            x = (x, x)\n",
    "        else:\n",
    "            x = (self.lin(x[0]), self.lin(x[1]))\n",
    "\n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x[1].size(self.node_dim))\n",
    "        out = self.propagate(edge_index, x=x, embedding=embedding, edges=edge_index, return_attention_weights=return_attention_weights)\n",
    "\n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        if return_attention_weights:\n",
    "            alpha, self.__alpha__ = self.__alpha__, None\n",
    "            return out, (edge_index, alpha)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index_i, size_i, embedding, edges, return_attention_weights):\n",
    "        x_i = x_i.view(-1, self.heads, self.out_channels)\n",
    "        x_j = x_j.view(-1, self.heads, self.out_channels)\n",
    "\n",
    "        if embedding is not None:\n",
    "            embedding_i, embedding_j = embedding[edge_index_i], embedding[edges[0]]\n",
    "            embedding_i = embedding_i.unsqueeze(1).repeat(1,self.heads,1)\n",
    "            embedding_j = embedding_j.unsqueeze(1).repeat(1,self.heads,1)\n",
    "\n",
    "            key_i = torch.cat((x_i, embedding_i), dim=-1)\n",
    "            key_j = torch.cat((x_j, embedding_j), dim=-1)\n",
    "\n",
    "        cat_att_i = torch.cat((self.att_i, self.att_em_i), dim=-1)\n",
    "        cat_att_j = torch.cat((self.att_j, self.att_em_j), dim=-1)\n",
    "        alpha = (key_i * cat_att_i).sum(-1) + (key_j * cat_att_j).sum(-1)\n",
    "        alpha = alpha.view(-1, self.heads, 1)\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = softmax(alpha, edge_index_i, num_nodes = size_i)\n",
    "\n",
    "        if return_attention_weights:\n",
    "            self.__alpha__ = alpha\n",
    "\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        return x_j * alpha.view(-1, self.heads, 1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, heads={})'.format(self.__class__.__name__, self.in_channels, self.out_channels, self.heads)\n",
    "\n",
    "    \n",
    "\n",
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, inter_dim=0, heads=1, node_num=100):\n",
    "        super(GNNLayer, self).__init__()\n",
    "        self.gnn = GraphLayer(in_channel, out_channel, inter_dim=inter_dim, heads=heads, concat=False)\n",
    "        self.bn = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, embedding=None, node_num=0):\n",
    "        out, (new_edge_index, att_weight) = self.gnn(x, edge_index, embedding, return_attention_weights=True)\n",
    "        self.att_weight_1 = att_weight\n",
    "        self.edge_index_1 = new_edge_index\n",
    "        out = self.bn(out)\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "488fa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphConv, self).__init__()\n",
    "        in_feats = 36\n",
    "        out_feats = 12\n",
    "        \n",
    "        self.gcn1 = GATConv(in_feats, out_feats)\n",
    "        self.gcn2 = GATConv(out_feats, out_feats)\n",
    "        self.linear = nn.Linear(out_feats, out_feats, bias = False)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbbcde91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphConv(\n",
      "  (gcn1): GATConv(36, 12, heads=1)\n",
      "  (gcn2): GATConv(12, 12, heads=1)\n",
      "  (linear): Linear(in_features=12, out_features=12, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GraphConv()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "837aeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_dataset, batch):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b10b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10746, 6)\n",
      "   requests_per_minute  request_duration  cpu_usage    memory        disk  \\\n",
      "0              30.6667         3157.2212     3.9381  676.4258  19798.1992   \n",
      "1              30.6667         3157.2212     3.9381  676.4258  19798.1992   \n",
      "2              25.3333         3208.7778     9.1459  668.0352  19798.3555   \n",
      "3              25.3333         3208.7778     9.1459  668.0352  19798.3555   \n",
      "4              25.3333         3208.7778     9.1459  668.0352  19798.3555   \n",
      "\n",
      "   network_load  \n",
      "0        0.0069  \n",
      "1        0.0069  \n",
      "2        0.3493  \n",
      "3        0.3493  \n",
      "4        0.3493  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('C:/Users/harsh/OneDrive/Desktop/notebooks/calaveras_telemetry_multi.csv')\n",
    "train_df = train_df.drop(columns = ['timestamp'])\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7da391f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10710, 36, 6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sequences(train_df, seq_len):\n",
    "    train_df = train_df.values\n",
    "    sequences = []\n",
    "    for i in range(len(train_df)):\n",
    "        j = i + seq_len\n",
    "        if j < len(train_df):\n",
    "            sequence = train_df[i:j, :]\n",
    "            sequences.append(sequence)\n",
    "    \n",
    "    sequences = np.array(sequences)\n",
    "    return sequences\n",
    "\n",
    "sequences = get_sequences(train_df, 36)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac182f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_loaders(sequences, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f76f5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_batch = sequences[:32]\n",
    "random_batch = sequences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2435e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00984728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_graph(num_nodes):\n",
    "    adj_matrix = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i!=j:\n",
    "                adj_matrix.append([i, j])\n",
    "    \n",
    "    return torch.tensor(adj_matrix, dtype=torch.long).t().contiguous()\n",
    "\n",
    "def node_feature(data):\n",
    "    data = torch.Tensor(data)\n",
    "    data = data.permute(0, 2, 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9833a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 6\n",
    "edge_index = dense_graph(num_nodes)\n",
    "x = node_feature(random_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81e01bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 36]), torch.Size([2, 30]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape, edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "583b9be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Static graphs not supported in 'GATConv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(x, edge_index)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\miniconda\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:202\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# We first transform the input node features. If a tuple is passed, we\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# transform source and target node features via separate weights:\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatic graphs not supported in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGATConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     x_src \u001b[38;5;241m=\u001b[39m x_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_src(x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, C)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Tuple of source and target node features:\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Static graphs not supported in 'GATConv'"
     ]
    }
   ],
   "source": [
    "out = model(x, edge_index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd16a1c2e981052eaae61151b9525ae9913f1f0d16bca6b7e7be9e0f29d739d2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
